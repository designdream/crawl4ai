name: Deploy Crawl4AI

on:
  push:
    branches: [ main ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  workflow_dispatch:  # Allow manual triggering

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1

      - name: Login to Docker Hub
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
          DOCKER_PASSWORD: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v2
        with:
          context: .
          push: true
          tags: ${{ secrets.DOCKERHUB_USERNAME }}/crawl4ai:latest
          platforms: linux/amd64  # For Digital Ocean compatibility

      - name: Deploy to Digital Ocean
        uses: appleboy/ssh-action@v0.1.4
        with:
          host: 164.92.69.88
          username: root
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            # Pull the latest image
            docker pull ${{ secrets.DOCKERHUB_USERNAME }}/crawl4ai:latest
            
            # Stop the current container
            docker stop crawl4ai-container || true
            docker rm crawl4ai-container || true
            
            # Run the new container with the same configuration
            docker run -d -p 80:8000 \
              -e "SECRET_KEY=${{ secrets.CRAWL4AI_SECRET_KEY }}" \
              -e "SECURITY_ENABLED=true" \
              -e "JWT_ENABLED=true" \
              -e "SCRAPINGBEE_API_KEY=${{ secrets.SCRAPINGBEE_API_KEY }}" \
              --restart always \
              --name crawl4ai-container \
              ${{ secrets.DOCKERHUB_USERNAME }}/crawl4ai:latest
            
            # Verify deployment
            sleep 5
            docker ps | grep crawl4ai-container
